# 一天搞懂深度学习

- Outline

  - Introduction of DL
  - Tips for Training DNN
  - Variants of NN
  - Next Wave

- Introduction

  - Step3
    - nn structure
    - learning target
    - learn
  - NN Structure
    - output=activation(input * weights+biases)
    - weight and biases are NN params
  - Target
    - minimize Total Loss
  - Learn
    - Gradient Desent
  - 应用
    - 图像识别
    - 垃圾邮件
  - Why Deep?

- Tips for Training DNN

  - Choosing proper Loss Method [crossentropy > square error]
  - Mini-batch
  - New activation function [relu > sigmoid]
    - vanishing gradient problem
  - Learning rete 
  - Momentum

- Overfitting : train is good but test is bad

  - Earlystopping [according to validation error]
  - Weight Decay
  - Droup out [only training step works]
  - Network Structure

- Variants of NN

  - CNN 

    - convolution
    - maxpooling
    - flatten

  - Recurrent NN

    - needs a lot of memory

  - Ultra Deep Network

  - Attention-based model

  - Reinforcement Learning

  - Unsupervised  Learning

  - Auto-encoder

  - Word Vector

    ​