{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a high-level API to build and train deep learning models. It's used for fast prototyping, advanced research, and production, with three key advantages:\n",
    "\n",
    "- User friendly\n",
    "Keras has a simple, consistent interface optimized for common use cases. It provides clear and actionable feedback for user errors.\n",
    "- Modular and composable\n",
    "Keras models are made by connecting configurable building blocks together, with few restrictions.\n",
    "- Easy to extend\n",
    "Write custom building blocks to express new ideas for research. Create new layers, loss functions, and develop state-of-the-art models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasonhaven/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# 1.Import tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn Keras, you assemble layers to build models.\\nA model is (usually) a graph of layers. \\nThe most common type of model is a stack of layers: \\n\\nthe tf.keras.Sequential model.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.Build a simple model\n",
    "# Sequential model\n",
    "'''\n",
    "In Keras, you assemble layers to build models.\n",
    "A model is (usually) a graph of layers. \n",
    "The most common type of model is a stack of layers: \n",
    "\n",
    "the tf.keras.Sequential model.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build a simple, fully-connected network (i.e. multi-layer perceptron):\n",
    "model=keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# Create a sigmoid layer by name:\\nkeras.layers.Dense(64, activation='sigmoid')\\n# Or by model:\\nkeras.layers.Dense(64, activation=tf.sigmoid)\\n\\n# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\\nkeras.layers.Dense(64, kernel_regularizer=keras.regularizers.l1(0.01))\\n# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\\nkeras.layers.Dense(64, bias_regularizer=keras.regularizers.l2(0.01))\\n\\n# A linear layer with a kernel initialized to a random orthogonal matrix:\\nkeras.layers.Dense(64, kernel_initializer='orthogonal')#正交\\n# A linear layer with a bias vector initialized to 2.0s:\\nkeras.layers.Dense(64, bias_initializer=keras.initializers.Constant(2.0))\\n\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.Configure the layers\n",
    "'''\n",
    "activation: Set the activation function for the layer. This parameter is specified by the name of a built-in function or as a callable object. By default, no activation is applied.\n",
    "kernel_initializer and bias_initializer: The initialization schemes that create the layer's weights (kernel and bias). This parameter is a name or a callable object. This defaults to the \"Glorot uniform\" initializer.\n",
    "kernel_regularizer and bias_regularizer: The regularization schemes that apply the layer's weights (kernel and bias), such as L1 or L2 regularization. By default, no regularization is applied.\n",
    "'''\n",
    "# Examples\n",
    "'''\n",
    "\n",
    "# Create a sigmoid layer by name:\n",
    "keras.layers.Dense(64, activation='sigmoid')\n",
    "# Or by model:\n",
    "keras.layers.Dense(64, activation=tf.sigmoid)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "keras.layers.Dense(64, kernel_regularizer=keras.regularizers.l1(0.01))\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "keras.layers.Dense(64, bias_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "keras.layers.Dense(64, kernel_initializer='orthogonal')#正交\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "keras.layers.Dense(64, bias_initializer=keras.initializers.Constant(2.0))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Configure a model for mean-squared error regression.\\nmodel.compile(optimizer=tf.train.AdamOptimizer(0.01),\\n              loss='mse',       # mean squared error\\n              metrics=['mae'])  # mean absolute error\\n\\n# Configure a model for categorical classification.\\nmodel.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\\n              loss=keras.losses.categorical_crossentropy,\\n              metrics=[keras.metrics.categorical_accuracy])\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1 Set up training\n",
    "'''\n",
    "three important arguments:\n",
    "optimizer,loss,metrics\n",
    "'''\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "# Examples\n",
    "'''\n",
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=[keras.metrics.categorical_accuracy])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 11.3789 - acc: 0.1010\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 11.3720 - acc: 0.1080\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 11.3672 - acc: 0.1120\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 11.3630 - acc: 0.1290\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 11.3597 - acc: 0.1120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f6c946e8ac8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.Input NumPy data\n",
    "# The model is \"fit\" to the training data using the fit method:\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 11.5483 - acc: 0.0990 - val_loss: 11.4009 - val_acc: 0.1200\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 11.5377 - acc: 0.1100 - val_loss: 11.3978 - val_acc: 0.1100\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 11.5324 - acc: 0.1140 - val_loss: 11.3978 - val_acc: 0.0900\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 11.5282 - acc: 0.1230 - val_loss: 11.3954 - val_acc: 0.1000\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 11.5235 - acc: 0.1300 - val_loss: 11.4000 - val_acc: 0.1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f6c946e3438>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's an example using validation_data:\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=5, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Instantiates a toy dataset instance:\\ndataset = tf.data.Dataset.from_tensor_slices((data, labels))\\ndataset = dataset.batch(32)\\ndataset = dataset.repeat()\\n\\n# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\\nmodel.fit(dataset, epochs=10, steps_per_epoch=30)\\n# steps_per_epoch argument—this is the number of training steps the model runs before it moves to the next epoch.\\n\\n\\n# Datasets can also be used for validation:\\ndataset = tf.data.Dataset.from_tensor_slices((data, labels))\\ndataset = dataset.batch(32).repeat()\\n\\nval_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\\nval_dataset = val_dataset.batch(32).repeat()\\n\\nmodel.fit(dataset, epochs=10, steps_per_epoch=30,\\n          validation_data=val_dataset,\\n          validation_steps=3)\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.Input tf.data datasets\n",
    "\n",
    "'''\n",
    "# Instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30)\n",
    "# steps_per_epoch argument—this is the number of training steps the model runs before it moves to the next epoch.\n",
    "\n",
    "\n",
    "# Datasets can also be used for validation:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32).repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=3)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.predict(x, batch_size=32)\\nmodel.predict(dataset, steps=30)\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.Evaluate and predict\n",
    "# numpy or dataset\n",
    "'''\n",
    "model.evaluate(x, y, batch_size=32)\n",
    "model.evaluate(dataset, steps=30)\n",
    "'''\n",
    "'''\n",
    "model.predict(x, batch_size=32)\n",
    "model.predict(dataset, steps=30)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.Build advanced models\n",
    "# 8.1 Functional API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.keras.Sequential model is a simple stack of layers that cannot represent arbitrary models. Use the Keras functional API to build complex model topologies such as:\n",
    "\n",
    "- Multi-input models,\n",
    "- Multi-output models,\n",
    "- Models with shared layers (the same layer called several times),\n",
    "- Models with non-sequential data flows (e.g. residual connections).\n",
    "\n",
    "Building a model with the functional API works like this:\n",
    "\n",
    "1. A layer instance is callable and returns a tensor.\n",
    "2. Input tensors and output tensors are used to define a tf.keras.Model  instance.\n",
    "3. This model is trained just like the Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 121us/step - loss: 11.6251 - acc: 0.1060\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 11.5770 - acc: 0.1040\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 11.5594 - acc: 0.1130\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 11.5510 - acc: 0.1120\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 11.5418 - acc: 0.1220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f6c946b9588>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the functional API to build a simple, fully-connected network:\n",
    "\n",
    "# inputs is a placeholder tensor\n",
    "inputs = keras.Input(shape=(32,))  # Returns a placeholder tensor\n",
    "\n",
    "# A layer instance is callable on a tensor, and returns a tensor.\n",
    "x = keras.layers.Dense(64, activation='relu')(inputs)\n",
    "x = keras.layers.Dense(64, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Instantiate the model given inputs and outputs.\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBuild a fully-customizable model by subclassing tf.keras.Model and defining your own forward pass.\\n\\n1.Create layers in the __init__ method and set them as attributes of the class instance\\n\\n2.Define the forward pass in the call method.\\n\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9.Model subclassing\n",
    "\n",
    "'''\n",
    "Build a fully-customizable model by subclassing tf.keras.Model and defining your own forward pass.\n",
    "\n",
    "1.Create layers in the __init__ method and set them as attributes of the class instance\n",
    "\n",
    "2.Define the forward pass in the call method.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 158us/step - loss: 11.5813 - acc: 0.0930\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 11.5701 - acc: 0.0880\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 11.5526 - acc: 0.0850\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 11.5440 - acc: 0.0970\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 11.5412 - acc: 0.0980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f6c946ca080>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel(keras.Model):\n",
    "\n",
    "  def __init__(self, num_classes=10):\n",
    "    super(MyModel, self).__init__(name='my_model')\n",
    "    self.num_classes = num_classes\n",
    "    # Define your layers here.\n",
    "    self.dense_1 = keras.layers.Dense(32, activation='relu')\n",
    "    self.dense_2 = keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Define your forward pass here,\n",
    "    # using layers you previously defined (in `__init__`).\n",
    "    x = self.dense_1(inputs)\n",
    "    return self.dense_2(x)\n",
    "\n",
    "  def compute_output_shape(self, input_shape):\n",
    "    # You need to override this function if you want to use the subclassed model\n",
    "    # as part of a functional-style model.\n",
    "    # Otherwise, this method is optional.\n",
    "    shape = tf.TensorShape(input_shape).as_list()\n",
    "    shape[-1] = self.num_classes\n",
    "    return tf.TensorShape(shape)\n",
    "\n",
    "\n",
    "# Instantiates the subclassed model.\n",
    "model = MyModel(num_classes=10)\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.TensorShape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreate a custom layer by subclassing tf.keras.layers.Layer and implementing the following methods:\\n\\nbuild: Create the weights of the layer. Add weights with the add_weight method.\\ncall: Define the forward pass.\\ncompute_output_shape: Specify how to compute the output shape of the layer given the input shape.\\nOptionally, a layer can be serialized by implementing the get_config method and the from_config class method.\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. Custom layers\n",
    "'''\n",
    "Create a custom layer by subclassing tf.keras.layers.Layer and implementing the following methods:\n",
    "\n",
    "build: Create the weights of the layer. Add weights with the add_weight method.\n",
    "call: Define the forward pass.\n",
    "compute_output_shape: Specify how to compute the output shape of the layer given the input shape.\n",
    "Optionally, a layer can be serialized by implementing the get_config method and the from_config class method.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 107us/step - loss: 13.2776 - acc: 0.0900\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 12.5980 - acc: 0.0950\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 12.1281 - acc: 0.0970\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 11.9996 - acc: 0.0920\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 11.9652 - acc: 0.0930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f6c604b9748>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Here's an example of a custom layer that implements a matmul of an input with a kernel matrix:\n",
    "'''\n",
    "class MyLayer(keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, output_dim, **kwargs):\n",
    "    self.output_dim = output_dim\n",
    "    super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
    "    # Create a trainable weight variable for this layer.\n",
    "    self.kernel = self.add_weight(name='kernel',\n",
    "                                  shape=shape,\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "    # Be sure to call this at the end\n",
    "    super(MyLayer, self).build(input_shape)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "  def compute_output_shape(self, input_shape):\n",
    "    shape = tf.TensorShape(input_shape).as_list()\n",
    "    shape[-1] = self.output_dim\n",
    "    return tf.TensorShape(shape)\n",
    "\n",
    "  def get_config(self):\n",
    "    base_config = super(MyLayer, self).get_config()\n",
    "    base_config['output_dim'] = self.output_dim\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "    return cls(**config)\n",
    "\n",
    "\n",
    "# Create a model using the custom layer\n",
    "model = keras.Sequential([MyLayer(10),\n",
    "                          keras.layers.Activation('softmax')])\n",
    "\n",
    "# The compile step specifies the training configuration\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 11.9296 - acc: 0.1120 - val_loss: 11.7765 - val_acc: 0.1100\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 11.9047 - acc: 0.1110 - val_loss: 11.7529 - val_acc: 0.1100\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 11.8805 - acc: 0.1130 - val_loss: 11.7325 - val_acc: 0.1200\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 11.8574 - acc: 0.1110 - val_loss: 11.7046 - val_acc: 0.1100\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 11.8343 - acc: 0.1200 - val_loss: 11.6877 - val_acc: 0.1100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f6c60782630>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11. Callbacks\n",
    "callbacks = [\n",
    "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
    "  keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"class_name\": \"Sequential\", \"config\": [{\"class_name\": \"MyLayer\", \"config\": null}, {\"class_name\": \"Activation\", \"config\": {\"name\": \"activation_3\", \"trainable\": true, \"dtype\": \"float32\", \"activation\": \"softmax\"}}], \"keras_version\": \"2.1.5-tf\", \"backend\": \"tensorflow\"}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: MyLayer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-68885482f7aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Recreate the model (freshly initialized)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mfresh_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Serializes a model to YAML format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    357\u001b[0m   \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    169\u001b[0m             custom_objects=dict(\n\u001b[1;32m    170\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    172\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m       \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m       \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m       \u001b[0marg_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown layer: MyLayer"
     ]
    }
   ],
   "source": [
    "# 12. Save and restore\n",
    "# 12.1 weights only\n",
    "'''\n",
    "Save and load the weights of a model using tf.keras.Model.save_weights:\n",
    "'''\n",
    "# Save weights to a TensorFlow Checkpoint file\n",
    "model.save_weights('./my_model')\n",
    "\n",
    "# Restore the model's state,\n",
    "# this requires a model with the same architecture.\n",
    "model.load_weights('my_model')\n",
    "'''\n",
    "By default, \n",
    "this saves the model's weights in the TensorFlow checkpoint file format.\n",
    "Weights can also be saved to the Keras HDF5 format (the default for the multi-backend implementation of Keras):\n",
    "'''\n",
    "# Save weights to a HDF5 file\n",
    "# model.save_weights('my_model.h5', save_format='h5') # 有问题\n",
    "\n",
    "# Restore the model's state\n",
    "# model.load_weights('my_model.h5')\n",
    "\n",
    "# 12.2 Configuration only\n",
    "'''\n",
    "A model's configuration can be saved—this serializes the model architecture without any weights. A saved configuration can recreate and initialize the same model, even without the code that defined the original model. Keras supports JSON and YAML serialization formats:\n",
    "'''\n",
    "# Serialize a model to JSON format\n",
    "json_string = model.to_json()\n",
    "print(json_string)\n",
    "\n",
    "# Recreate the model (freshly initialized)\n",
    "fresh_model = keras.models.model_from_json(json_string)\n",
    "\n",
    "# Serializes a model to YAML format\n",
    "yaml_string = model.to_yaml()\n",
    "print(yaml_string)\n",
    "\n",
    "# Recreate the model\n",
    "fresh_model = keras.models.model_from_yaml(yaml_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.model_from_json?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 153us/step - loss: 11.5494 - acc: 0.1140\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 11.5435 - acc: 0.1120\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 11.5417 - acc: 0.1100\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 11.5409 - acc: 0.1210\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 11.5402 - acc: 0.1160\n"
     ]
    }
   ],
   "source": [
    "# 12.3 Entire model\n",
    "\n",
    "# Create a trivial model\n",
    "model = keras.Sequential([\n",
    "  keras.layers.Dense(10, activation='softmax', input_shape=(32,)),\n",
    "  keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels, batch_size=32, epochs=5)\n",
    "\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('my_model.h5')\n",
    "\n",
    "# Recreate the exact same model, including weights and optimizer.\n",
    "model = keras.models.load_model('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7f65225f22b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./my_model.h5',save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
